{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import quandl\n",
    "import MetaTrader5 as mt5\n",
    "from binance.spot import Spot\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga de históricos de Metatrader 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_metatrader5_data(symbol, start_date, end_date, timeframe):\n",
    "    if mt5.initialize():\n",
    "        max_bars = 1000\n",
    "        timeframe_to_seconds = {\n",
    "            mt5.TIMEFRAME_M1: 60,\n",
    "            mt5.TIMEFRAME_M5: 300,\n",
    "            mt5.TIMEFRAME_M15: 900,\n",
    "            mt5.TIMEFRAME_M30: 1800,\n",
    "            mt5.TIMEFRAME_H1: 3600,\n",
    "            mt5.TIMEFRAME_H4: 14400,\n",
    "            mt5.TIMEFRAME_D1: 86400,\n",
    "            mt5.TIMEFRAME_W1: 604800\n",
    "        }\n",
    "        max_seconds = max_bars * timeframe_to_seconds[timeframe]\n",
    "        delta = timedelta(seconds=max_seconds)\n",
    "        data_frames = []\n",
    "        while start_date < end_date:\n",
    "            try:\n",
    "                temp_end_date = min(start_date + delta, end_date)\n",
    "            except OverflowError:\n",
    "                print('Se ha dado la Exception')\n",
    "                temp_end_date = end_date\n",
    "            #print(f\"{start_date} - {temp_end_date}\")\n",
    "            rates = mt5.copy_rates_range(symbol, timeframe, start_date, temp_end_date)\n",
    "            if rates is not None and rates.size > 0:\n",
    "                df = pd.DataFrame(rates[['time', 'open', 'high', 'low', 'close', 'tick_volume']])\n",
    "                df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "                data_frames.append(df)\n",
    "            start_date = temp_end_date + timedelta(seconds=timeframe_to_seconds[timeframe])\n",
    "        full_df = pd.concat(data_frames, ignore_index=True)\n",
    "        if full_df['time'].duplicated().any():\n",
    "            full_df = full_df.drop_duplicates(subset='time', keep='first')\n",
    "        full_df = full_df.set_index('time').sort_index(ascending=True)\n",
    "        return full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga de históricos de Binance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_binance_data(symbols, interval='1d'):\n",
    "    def get_api_secret():\n",
    "        import os\n",
    "        import gnupg\n",
    "        import keyring\n",
    "\n",
    "        gpg = gnupg.GPG()\n",
    "        encrypted_file_path = os.path.expanduser('~/Repositorios/.env.gpg')\n",
    "        with open(encrypted_file_path, 'rb') as file:\n",
    "            datos = gpg.decrypt_file(file, passphrase=keyring.get_password(\"GPG_Passphrase\", \"gpg_python\"))\n",
    "        if datos.ok:\n",
    "            env_vars = dict(line.decode('utf-8').split('=', 1) for line in datos.data.splitlines())\n",
    "            api_key = env_vars.get('API_KEY')\n",
    "            secret_key = env_vars.get('SECRET_KEY')\n",
    "            return api_key, secret_key\n",
    "\n",
    "    # Inicializa el cliente de Binance\n",
    "    api_key, secret_key = get_api_secret()\n",
    "    client = Spot(api_key, secret_key)\n",
    "\n",
    "    data_frames = {}\n",
    "    for symbol in symbols:\n",
    "        start_time = 0\n",
    "        data = []\n",
    "        while True:\n",
    "            # Obtener datos de klines\n",
    "            klines = client.klines(symbol=symbol, interval=interval, limit=1000, startTime=start_time)\n",
    "            # Si no hay más datos, salir del bucle\n",
    "            if not klines:\n",
    "                break\n",
    "            for kline in klines:\n",
    "                data.append({\n",
    "                    'open_time': kline[0],\n",
    "                    'open': float(kline[1]),\n",
    "                    'high': float(kline[2]),\n",
    "                    'low': float(kline[3]),\n",
    "                    'close': float(kline[4]),\n",
    "                    'volume': float(kline[5]),\n",
    "                    'quote': float(kline[7]),\n",
    "                    'trades': float(kline[8]),\n",
    "                    'buy_quote': float(kline[9]),\n",
    "                    'buy_base': float(kline[10])\n",
    "                })\n",
    "            # Actualizar start_time para la próxima solicitud\n",
    "            start_time = klines[-1][0] + 1\n",
    "        data_frames[symbol] = pd.DataFrame(data)\n",
    "    # Crear el dataframe multinivel\n",
    "    df_list = []\n",
    "    for symbol, df in data_frames.items():\n",
    "        df = df.set_index('open_time')\n",
    "        df.index.name = 'date'\n",
    "        df.index = pd.to_datetime(df.index, unit='ms')\n",
    "        if len(symbols) > 1:\n",
    "            df.columns = pd.MultiIndex.from_product([[symbol], df.columns])\n",
    "        df_list.append(df)\n",
    "    final_df = pd.concat(df_list, axis=1)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga históricos de BitStamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_bitstamp_data(symbol, start, end, timeframe, limit=1000):\n",
    "    url = f\"https://www.bitstamp.net/api/v2/ohlc/{symbol}/\"\n",
    "    data_frames = []\n",
    "    while start < end:\n",
    "        # Ajustar end para la solicitud actual para no exceder el límite de 1000 registros\n",
    "        current_end = start + (timeframe * limit)\n",
    "        # Debug\n",
    "        #print(f\"{pd.to_datetime(start, unit='s')} - {pd.to_datetime(current_end, unit='s')}\")\n",
    "        params = {\n",
    "            'start': int(start),\n",
    "            'end': int(current_end),\n",
    "            'step': timeframe,\n",
    "            'limit': limit,\n",
    "            'exclude_current_candle': False\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                df = pd.DataFrame(data['data']['ohlc'])\n",
    "                if not df.empty:\n",
    "                    data_frames.append(df)\n",
    "            else:\n",
    "                raise Exception(f\"Failed to fetch data: {response.status_code}, {response.text}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "        start = current_end\n",
    "    # Combinar todos los DataFrames\n",
    "    if data_frames:\n",
    "        df = pd.concat(data_frames, ignore_index=True)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "        df = df.set_index('timestamp')\n",
    "        df = df.sort_index()\n",
    "        df.index.name = 'date'\n",
    "        df = df.astype({\n",
    "            'open': float,\n",
    "            'high': float,\n",
    "            'low': float,\n",
    "            'close': float,\n",
    "            'volume': float\n",
    "        })\n",
    "        # Comprobar filas duplicadas\n",
    "        if df.index.duplicated().any():\n",
    "            df = df[~df.index.duplicated(keep='first')]\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga de métricas blockchain de BTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_quandl_bchain_data():\n",
    "    # API de Quandl\n",
    "    quandl.ApiConfig.api_key = 'dmZf3xLBsRjidx-o1urg'\n",
    "    # Lista de códigos de las métricas\n",
    "    metrics_codes = [\n",
    "        'MKPRU', 'MWNUS', 'HRATE', 'DIFF', 'MKPRU', 'MIREV', 'CPTRA',\n",
    "        'TRVOU', 'CPTRV', 'ETRVU', 'ETRAV', 'TOUTV', 'NTRBL', 'NTRAT',\n",
    "        'NADDU', 'NTREP', 'NTRAN', 'TRFUS', 'TRFEE', 'MKTCP', 'TOTBC',\n",
    "        'MWNTD', 'MWTRV'\n",
    "    ]\n",
    "    # Diccionario para almacenar los dataframes\n",
    "    dfs = {}\n",
    "    for code in metrics_codes:\n",
    "        # Obtener la tabla de Quandl para cada métrica\n",
    "        df = quandl.get_table('QDL/BCHAIN', code=code)\n",
    "        # Almacenar el DataFrame en el diccionario con el código como clave\n",
    "        dfs[code] = df.set_index('date')[['value']].rename(columns={'value': code})\n",
    "    # Concatenar todos los DataFrames a lo largo del eje de las columnas\n",
    "    return pd.concat(dfs.values(), axis=1, join='outer')\n",
    "    \"\"\"\n",
    "    # Calcular las medias móviles\n",
    "    df['SMA30'] = df['HRATE'].rolling(window=30).mean()\n",
    "    df['SMA60'] = df['HRATE'].rolling(window=60).mean()\n",
    "    # Detectar señales de capitulación y recuperación\n",
    "    df['Capitulation'] = df['SMA30'] < df['SMA60']\n",
    "    df['Buy_Signal'] = (df['SMA30'] > df['SMA60']) & (df['Capitulation'].shift(1) == True)\n",
    "    df['Sell_Signal'] = (df['SMA30'] < df['SMA60']) & (df['Capitulation'].shift(1) == False)\n",
    "    # Visualización\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    #plt.plot(df.index, df['HRATE'], label='Hash Rate')\n",
    "    plt.plot(df.index, df['SMA30'], label='30-Day SMA', color='orange')\n",
    "    plt.plot(df.index, df['SMA60'], label='60-Day SMA', color='green')\n",
    "    plt.scatter(df.index[df['Buy_Signal']], df['SMA30'][df['Buy_Signal']], color='green', label='Buy Signal', marker='^', s=100)\n",
    "    plt.scatter(df.index[df['Sell_Signal']], df['SMA30'][df['Sell_Signal']], color='red', label='Sell Signal', marker='v', s=100) \n",
    "    plt.title('Hash Rate and Moving Averages')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marca de tiempo de máximos y mínimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_timestamp_extremum(df_highest, df_lowest):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        df_highest_timeframe(highest timeframe OHLCV dataframe)\n",
    "        df_lowest_timeframe(lowest timeframe OHLCV dataframe)\n",
    "    \"\"\"\n",
    "    # Añadir nuevas columnas si no existen\n",
    "    for col in ['Low_time', 'High_time', 'First']:\n",
    "        if col not in df_highest.columns:\n",
    "            df_highest[col] = np.nan\n",
    "    # Establecer qué sucedió antes si High o Low\n",
    "    index_starts = df_highest.index[:-1]\n",
    "    index_ends = df_highest.index[1:]\n",
    "    for start, end in zip(index_starts, index_ends):\n",
    "        row_lowest_timeframe = df_lowest.loc[start:end]\n",
    "        if len(row_lowest_timeframe) > 1:\n",
    "            row_lowest_timeframe = row_lowest_timeframe.iloc[:-1]\n",
    "        try:\n",
    "            high = row_lowest_timeframe['high'].idxmax()\n",
    "            low = row_lowest_timeframe['low'].idxmin()\n",
    "            df_highest.loc[start, 'High_time'] = high\n",
    "            df_highest.loc[start, 'Low_time'] = low\n",
    "        except Exception as e:\n",
    "            print(f'Exception occurred: {e}')\n",
    "            df_highest.loc[start, 'High_time'] = start\n",
    "            df_highest.loc[start, 'Low_time'] = start\n",
    "    # Asegurar que las columnas son de tipo datetime\n",
    "    df_highest['High_time'] = pd.to_datetime(df_highest['High_time'])\n",
    "    df_highest['Low_time'] = pd.to_datetime(df_highest['Low_time'])\n",
    "    # Find out which appears first\n",
    "    df_highest.loc[df_highest['High_time'] > df_highest['Low_time'], 'First'] = 1\n",
    "    df_highest.loc[df_highest['High_time'] < df_highest['Low_time'], 'First'] = 2\n",
    "    df_highest.loc[df_highest['High_time'] == df_highest['Low_time'], 'First'] = 0\n",
    "    # Verificar el número de filas sin TP ni SL al mismo tiempo\n",
    "    percentage_garbage_row = len(df_highest.loc[df_highest['First']==0].dropna()) / len(df_highest) * 100.\n",
    "    print(f'WARNING: Filas no válidas para establecer TP/SL: {percentage_garbage_row:.2f} %')\n",
    "    # Remover la última columna porque no es posible encontrar el extremo\n",
    "    df_highest = df_highest.iloc[:-1]\n",
    "    return df_highest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de TP y SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tp_sl(data, data_lowest, leverage=1, tp=0.015, sl=-0.015, cost=0.00, tsl=None):\n",
    "    '''\n",
    "    params (mandatory): \n",
    "        df - DataFrame with High_time and Low_time columns\n",
    "    params (optional):\n",
    "        leverage=1, tp_0.015, ls=-0.015, cost=0.00\n",
    "    return:\n",
    "        df - Incoming DataFrame with two new columns ['returns', 'duration']\n",
    "    '''\n",
    "    # Encontrar marca de tiempo de máximos y mínimos\n",
    "    df = find_timestamp_extremum(data, data_lowest)\n",
    "    # Si trailing stop\n",
    "    tpl = tp - tsl if tsl is not None else tp\n",
    "    # El trade comienza en la SIGUIENTE vela\n",
    "    signal_column = df['signal']\n",
    "    df['signal'] = df['signal'].shift(1).fillna(0)\n",
    "    # Establecer valores iniciales\n",
    "    buy = False\n",
    "    sell = False\n",
    "    df['duration'] = 0\n",
    "    # Bucle principal\n",
    "    for i in range(len(df)):\n",
    "        # Extraer fila\n",
    "        row = df.iloc[i]\n",
    "        # ABRIR COMPRA\n",
    "        if buy == False and row['signal'] == 1:\n",
    "            buy = True\n",
    "            open_buy_price = row['open']\n",
    "            open_buy_date = row.name\n",
    "        if buy:\n",
    "            # Verificar variación\n",
    "            var_buy_high = (row['high'] - open_buy_price) / open_buy_price\n",
    "            var_buy_low = (row['low'] - open_buy_price) / open_buy_price\n",
    "            # Comprobar localización de TP y SL\n",
    "            if (var_buy_high > tp) and (var_buy_low < sl):\n",
    "                # Si ambos tienen el mismo timestamp, no se considera el trade\n",
    "                if row[\"First\"] == 0:\n",
    "                    pass\n",
    "                elif row['First'] == 2:\n",
    "                    df.loc[row.name, 'returns'] = (tpl - cost) * leverage\n",
    "                    df.loc[row.name, 'duration'] = row['High_time'] - open_buy_date\n",
    "                elif row['First'] == 1:\n",
    "                    df.loc[row.name, 'returns'] = (sl - cost) * leverage\n",
    "                    df.loc[row.name, 'duration'] = row['Low_time'] - open_buy_date\n",
    "                # Resetear valores\n",
    "                buy = False\n",
    "                open_buy_price = None\n",
    "                var_buy_high = 0\n",
    "                var_buy_low = 0\n",
    "                open_buy_date = None\n",
    "            elif var_buy_high > tp:\n",
    "                df.loc[row.name, 'returns'] = (tpl - cost) * leverage\n",
    "                df.loc[row.name, 'duration'] = row['High_time'] - open_buy_date\n",
    "                # Resetear valores\n",
    "                buy = False\n",
    "                open_buy_price = None\n",
    "                var_buy_high = 0\n",
    "                var_buy_low = 0\n",
    "                open_buy_date = None\n",
    "            elif var_buy_low < sl:\n",
    "                df.loc[row.name, 'returns'] = (sl - cost) * leverage\n",
    "                df.loc[row.name, 'duration'] = row['Low_time'] - open_buy_date\n",
    "                # Resetear valores\n",
    "                buy = False\n",
    "                open_buy_price = None\n",
    "                var_buy_high = 0\n",
    "                var_buy_low = 0\n",
    "                open_buy_date = None\n",
    "        # ABRIR VENTA\n",
    "        if sell == False and row['signal'] == -1:\n",
    "            sell = True\n",
    "            open_sell_price = row['open']\n",
    "            open_sell_date = row.name\n",
    "        if sell:\n",
    "            # Verificar variación\n",
    "            var_sell_high = -(row['high'] - open_sell_price) / open_sell_price\n",
    "            var_sell_low = -(row['low'] - open_sell_price) / open_sell_price\n",
    "            # Comprobar localización de TP y SL\n",
    "            if (var_sell_low > tp) and (var_sell_high < sl):\n",
    "                # Si ambos tienen el mismo timestamp, no se considera el trade\n",
    "                if row['First'] == 0:\n",
    "                    pass\n",
    "                elif row['First'] == 1:\n",
    "                    df.loc[row.name, 'returns'] = (tpl - cost) * leverage\n",
    "                    df.loc[row.name, 'duration'] = row['Low_time'] - open_sell_date\n",
    "                elif row['First'] == 2:\n",
    "                    df.loc[row.name, 'returns'] = (sl - cost) * leverage\n",
    "                    df.loc[row.name, 'duration'] = row['High_time'] - open_sell_date\n",
    "                # Resetear valores\n",
    "                sell = False\n",
    "                open_sell_price = None\n",
    "                var_sell_high = 0\n",
    "                var_sell_low = 0\n",
    "                open_sell_date = None\n",
    "            elif var_sell_low > tp:\n",
    "                df.loc[row.name, 'returns'] = (tpl - cost) * leverage\n",
    "                df.loc[row.name, 'duration'] = row['Low_time'] - open_sell_date\n",
    "                # Resetear valores\n",
    "                sell = False\n",
    "                open_sell_price = None\n",
    "                var_sell_high = 0\n",
    "                var_sell_low = 0\n",
    "                open_sell_date = None\n",
    "            elif var_sell_high < sl:\n",
    "                df.loc[row.name, 'returns'] = (sl - cost) * leverage\n",
    "                df.loc[row.name, 'duration'] = row['High_time'] - open_sell_date\n",
    "                # Resetear valores\n",
    "                sell = False\n",
    "                open_sell_price = None\n",
    "                var_sell_high = 0\n",
    "                var_sell_low = 0\n",
    "                open_sell_date = None\n",
    "    # Eliminar columnas inncesarias\n",
    "    df = df.drop(labels=['Low_time', 'High_time'], axis=1)\n",
    "    # Rellenar con 0s valores faltantes\n",
    "    df['returns'] = df['returns'].fillna(value=0)\n",
    "    # Reestablecer señal\n",
    "    df['signal'] = signal_column\n",
    "    # retornar df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beneficios menusales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profitable_month_return(returns):\n",
    "    returns_series = returns * 100.\n",
    "    # Calcular los rendimientos mensuales\n",
    "    monthly_returns = returns_series.resample('M').sum()\n",
    "\n",
    "    # Agrupar por año y mes\n",
    "    monthly_returns_by_year = returns_series.resample('M').sum().groupby([monthly_returns.index.year, monthly_returns.index.month]).sum()\n",
    "\n",
    "    # Renombrar los índices\n",
    "    monthly_returns_by_year.index.names = ['Year', 'Month']\n",
    "\n",
    "    # Crear tabla pivotada\n",
    "    pivot_table = monthly_returns_by_year.unstack(level=-1)\n",
    "\n",
    "    # Mostrar la tabla pivotada\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    pal = sns.color_palette('RdYlGn', n_colors=15)\n",
    "    sns.heatmap(pivot_table, annot=True, cmap=pal)\n",
    "    plt.title('Heatmap Monthly Returns')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulación de Montecarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montecarlo_simulation(data, method='simple', num_simulations=100, percentiles=[1, 50, 99], seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    data = data[data != 0]\n",
    "    random_returns = []\n",
    "    for _ in range(num_simulations):\n",
    "        returns = np.random.permutation(data)\n",
    "        random_returns.append(returns)\n",
    "    df_ret = pd.DataFrame(random_returns).transpose()\n",
    "    if method == 'simple':\n",
    "        df_ret = df_ret.cumsum() * 100\n",
    "        cur_ret = data.cumsum() * 100\n",
    "    elif method == 'compounded':\n",
    "        df_ret = ((1 + df_ret).cumprod() - 1) * 100\n",
    "        cur_ret = ((1 + data).cumprod() - 1) * 100\n",
    "    # Calcular percentiles\n",
    "    p_0 = np.percentile(df_ret, percentiles[0], axis=1)\n",
    "    p_1 = np.percentile(df_ret, percentiles[1], axis=1)\n",
    "    p_2 = np.percentile(df_ret, percentiles[2], axis=1)\n",
    "    \n",
    "    # Visualización\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(df_ret.index, p_0, color='#39B3C7')\n",
    "    plt.plot(df_ret.index, p_1, color='#39B3C7')\n",
    "    plt.plot(df_ret.index, p_2, color='#39B3C7')\n",
    "    plt.plot(df_ret.index, cur_ret, color='blue', alpha=0.60, linewidth=3, label='Current Returns')\n",
    "    plt.fill_between(df_ret.index, p_2, p_0, color='#669FEE', alpha=0.2, label='Montecarlo Area')\n",
    "    plt.ylabel('Cumulative returns %', size=13)\n",
    "    plt.title('Montecarlo Simulation', size=20)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
